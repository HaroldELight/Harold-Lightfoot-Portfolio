{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps I took to combine the various functions into a final Class\n",
    "### (Included to exhibit the process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Speech to text\n",
    "# 2. Processing\n",
    "# 3. Text to Speech\n",
    "# 4. One function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import speech_recognition as sr\n",
    "import os \n",
    "import pyaudio\n",
    "from gtts import gTTS\n",
    "import google.generativeai\n",
    "import wave\n",
    "import threading\n",
    "import configparser\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Speech to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio():\n",
    "    # Parameters for recording\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 1\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    OUTPUT_FILENAME = \"Recording.wav\"\n",
    "    is_recording = True\n",
    "\n",
    "    def record_audio_logic():\n",
    "        # Initialize PyAudio\n",
    "        audio = pyaudio.PyAudio()\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "        frames = []\n",
    "        print(\"Recording... Press 'q' to stop.\")\n",
    "\n",
    "        while is_recording:  # Controlled by outer scope\n",
    "            frames.append(stream.read(CHUNK))\n",
    "\n",
    "        # Clean up resources after stopping\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "\n",
    "        # Save the audio to a file\n",
    "        with wave.open(OUTPUT_FILENAME, \"wb\") as wf:\n",
    "            wf.setnchannels(CHANNELS)\n",
    "            wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "            wf.setframerate(RATE)\n",
    "            wf.writeframes(b\"\".join(frames))\n",
    "        print(f\"Saved audio to: {os.path.abspath(OUTPUT_FILENAME)}\")\n",
    "\n",
    "    # Function to stop recording when \"q\" is pressed\n",
    "    def stop_recording():\n",
    "        nonlocal is_recording\n",
    "        while input() != \"q\":\n",
    "            pass\n",
    "        is_recording = False\n",
    "\n",
    "    # Threading for simultaneous recording and stopping\n",
    "    thread = threading.Thread(target=record_audio_logic)\n",
    "    thread.start()\n",
    "    stop_recording()  # Monitor user input\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goeiedag hoe gaan dit\n"
     ]
    }
   ],
   "source": [
    "audio_file = 'Recording.wav'\n",
    "\n",
    "def speech_to_text(audio_file):\n",
    "    recognizer = sr.Recognizer()\n",
    "    with sr.AudioFile(audio_file) as source:\n",
    "        audio = recognizer.record(source)\n",
    "        text = recognizer.recognize_google(audio, language='af-ZA') # Afrikaans\n",
    "    #print(text)\n",
    "    return text\n",
    "\n",
    "user_prompt = speech_to_text(audio_file)\n",
    "print(user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gogo_response(user_prompt):\n",
    "    \"\"\"\n",
    "    Generate a response to the user's prompt using the Gemini model.\n",
    "\n",
    "    Args:\n",
    "        user_prompt (str): The user's prompt or question.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated response in AFRIKAANS\n",
    "    \"\"\"\n",
    "    # Define the system message for the generative model\n",
    "    system_message = 'This is Afrikaans text, you will respond in Afrikaans \\\n",
    "    and you are a helpful assistant.'\n",
    "\n",
    "    # Set the Google API key (use environment variable if available, otherwise use hardcoded key)\n",
    "    gog_key = config.get('API_KEYS', 'google_api_key')\n",
    "    \n",
    "    # Configure the Google Generative AI library\n",
    "    google.generativeai.configure(api_key=os.environ.get('GOOGLE_API_KEY', gog_key))\n",
    "\n",
    "    # Create a Gemini model instance with the system instruction\n",
    "    gemini = google.generativeai.GenerativeModel(\n",
    "        model_name='gemini-1.5-flash',\n",
    "        system_instruction=system_message\n",
    "    )\n",
    "\n",
    "    # Generate content using the Gemini model\n",
    "    response = gemini.generate_content(user_prompt)\n",
    "\n",
    "    # Return the generated response text\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goeiedag! Dit gaan goed, dankie.  En hoe gaan dit met jou?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = Gogo_response(user_prompt)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'gogo_response.mp3'\n",
    "\n",
    "def text_to_audio(text, filename):\n",
    "    tts = gTTS(text=text, lang='af')\n",
    "    tts.save(filename)\n",
    "\n",
    "    # Play the audio file\n",
    "    os.system(f\"start {filename}\")\n",
    "\n",
    "text_to_audio(text, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. One Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speech to text\n",
    "\n",
    "class Afri_chatbot:\n",
    "    def record_audio():\n",
    "        # Parameters for recording\n",
    "        FORMAT = pyaudio.paInt16\n",
    "        CHANNELS = 1\n",
    "        RATE = 44100\n",
    "        CHUNK = 1024\n",
    "        OUTPUT_FILENAME = \"Recording.wav\"\n",
    "        is_recording = True\n",
    "\n",
    "        def record_audio_logic():\n",
    "            # Initialize PyAudio\n",
    "            audio = pyaudio.PyAudio()\n",
    "            stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "            frames = []\n",
    "            print(\"Recording... Press 'q' to stop.\")\n",
    "\n",
    "            while is_recording:  # Controlled by outer scope\n",
    "                frames.append(stream.read(CHUNK))\n",
    "\n",
    "            # Clean up resources after stopping\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            audio.terminate()\n",
    "\n",
    "            # Save the audio to a file\n",
    "            with wave.open(OUTPUT_FILENAME, \"wb\") as wf:\n",
    "                wf.setnchannels(CHANNELS)\n",
    "                wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "                wf.setframerate(RATE)\n",
    "                wf.writeframes(b\"\".join(frames))\n",
    "            print(f\"Saved audio to: {os.path.abspath(OUTPUT_FILENAME)}\")\n",
    "\n",
    "        # Function to stop recording when \"q\" is pressed\n",
    "        def stop_recording():\n",
    "            nonlocal is_recording\n",
    "            while input() != \"q\":\n",
    "                pass\n",
    "            is_recording = False\n",
    "\n",
    "        # Threading for simultaneous recording and stopping\n",
    "        thread = threading.Thread(target=record_audio_logic)\n",
    "        thread.start()\n",
    "        stop_recording()  # Monitor user input\n",
    "        thread.join()\n",
    "\n",
    "    record_audio()\n",
    "    audio_file = 'Recording.wav'\n",
    "\n",
    "    # Audio file to text\n",
    "    def speech_to_text(audio_file):\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(audio_file) as source:\n",
    "            audio = recognizer.record(source)\n",
    "            user_prompt = recognizer.recognize_google(audio, language='af-ZA') # Afrikaans\n",
    "        #print(text)\n",
    "        return user_prompt\n",
    "\n",
    "    user_prompt = speech_to_text(audio_file)\n",
    "    print(user_prompt)\n",
    "\n",
    "    # Processing\n",
    "\n",
    "    def Gogo_response(user_prompt):\n",
    "        \"\"\"\n",
    "        Generate a response to the user's prompt using the Gemini model.\n",
    "\n",
    "        Args:\n",
    "            user_prompt (str): The user's prompt or question.\n",
    "\n",
    "        Returns:\n",
    "            str: The generated response in AFRIKAANS\n",
    "        \"\"\"\n",
    "        # Define the system message for the generative model\n",
    "        system_message = 'This is Afrikaans text, you will respond in Afrikaans \\\n",
    "        and you are a helpful assistant.'\n",
    "\n",
    "        # Set the Google API key (use environment variable if available, otherwise use hardcoded key)\n",
    "        gog_key = config.get('API_KEYS', 'google_api_key')\n",
    "        \n",
    "        # Configure the Google Generative AI library\n",
    "        google.generativeai.configure(api_key=os.environ.get('GOOGLE_API_KEY', gog_key))\n",
    "\n",
    "        # Create a Gemini model instance with the system instruction\n",
    "        gemini = google.generativeai.GenerativeModel(\n",
    "            model_name='gemini-1.5-flash',\n",
    "            system_instruction=system_message\n",
    "        )\n",
    "\n",
    "        # Generate content using the Gemini model\n",
    "        response = gemini.generate_content(user_prompt)\n",
    "\n",
    "        # Return the generated response text\n",
    "        return response.text\n",
    "\n",
    "    text = Gogo_response(user_prompt)\n",
    "    print(text)\n",
    "\n",
    "    # Text to speech\n",
    "\n",
    "    filename = 'gogo_response.mp3'\n",
    "\n",
    "    def text_to_audio(text, filename):\n",
    "        tts = gTTS(text=text, lang='af')\n",
    "        tts.save(filename)\n",
    "\n",
    "        # Play the audio file\n",
    "        os.system(f\"start {filename}\")\n",
    "\n",
    "    text_to_audio(text, filename)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some AI help to package into workable class\n",
    "\n",
    "class Katrina:\n",
    "    def __init__(self):\n",
    "        self.is_recording = True\n",
    "        self.audio_file = \"Recording.wav\"\n",
    "        self.filename = \"Katrina.mp3\"\n",
    "\n",
    "    def record_audio(self):\n",
    "        FORMAT = pyaudio.paInt16\n",
    "        CHANNELS = 1\n",
    "        RATE = 44100\n",
    "        CHUNK = 1024\n",
    "\n",
    "        def record_audio_logic():\n",
    "            audio = pyaudio.PyAudio()\n",
    "            stream = audio.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True, frames_per_buffer=CHUNK)\n",
    "            frames = []\n",
    "            print(\"Recording... Press 'q' to stop.\")\n",
    "\n",
    "            while self.is_recording:\n",
    "                frames.append(stream.read(CHUNK))\n",
    "\n",
    "            stream.stop_stream()\n",
    "            stream.close()\n",
    "            audio.terminate()\n",
    "\n",
    "            with wave.open(self.audio_file, \"wb\") as wf:\n",
    "                wf.setnchannels(CHANNELS)\n",
    "                wf.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "                wf.setframerate(RATE)\n",
    "                wf.writeframes(b\"\".join(frames))\n",
    "            print(f\"Saved audio to: {os.path.abspath(self.audio_file)}\")\n",
    "\n",
    "        def stop_recording():\n",
    "            while input() != \"q\":\n",
    "                pass\n",
    "            self.is_recording = False\n",
    "\n",
    "        thread = threading.Thread(target=record_audio_logic)\n",
    "        thread.start()\n",
    "        stop_recording()\n",
    "        thread.join()\n",
    "\n",
    "    def speech_to_text(self):\n",
    "        recognizer = sr.Recognizer()\n",
    "        with sr.AudioFile(self.audio_file) as source:\n",
    "            audio = recognizer.record(source)\n",
    "            return recognizer.recognize_google(audio, language=\"af-ZA\")\n",
    "\n",
    "    def Gogo_response(self, user_prompt):\n",
    "        \n",
    "        # Kept short and sweet\n",
    "        system_message = 'You are Katrina, you respond in Afrikaans with less than 30 words.'\n",
    "\n",
    "        # Read the API key from the config file\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read('config.ini')\n",
    "\n",
    "        # Get the Google API key from the config file\n",
    "        gog_key = config.get('API_KEYS', 'google_api_key')\n",
    "\n",
    "        # Configure the Google Generative AI library\n",
    "        google.generativeai.configure(api_key=gog_key)\n",
    "\n",
    "        # Create a Gemini model instance\n",
    "        gemini = google.generativeai.GenerativeModel(\n",
    "            model_name=\"gemini-1.5-flash\",\n",
    "            system_instruction='This is Afrikaans text, you will respond in Afrikaans and you are a helpful assistant.'\n",
    "        )\n",
    "\n",
    "        # Generate content using the Gemini model\n",
    "        response = gemini.generate_content(user_prompt)\n",
    "        return response.text\n",
    "\n",
    "    def text_to_audio(self, text):\n",
    "        \n",
    "        tts = gTTS(text=text, lang=\"af\")\n",
    "        tts.save(self.filename)\n",
    "        os.system(f\"start {self.filename}\")\n",
    "\n",
    "    def run(self):\n",
    "        self.record_audio()\n",
    "        user_prompt = self.speech_to_text()\n",
    "        print(f\"User said: {user_prompt}\")\n",
    "        response = self.Gogo_response(user_prompt)\n",
    "        #print(f\"Bot response: {response}\")\n",
    "        self.text_to_audio(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the class\n",
    "\n",
    "Katrina().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio response in Afrikaans to default media player"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
